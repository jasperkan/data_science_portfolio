{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Legendary Status of a Pokemon Using Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this project is to predict whether the Pokemon is a legendary Pokemon. The dataset used is available on Kaggle (https://www.kaggle.com/abcsds/pokemon). It contains basic stats for 721 Pokemons, such as HP, Attack, Defense, Special Attack, Special Defense, and Speed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Used\n",
    "- pokemon_data_science.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Procedure to Train Logistic Regression Model\n",
    "\n",
    "1. Prepare and transform the data\n",
    "2. Split dataset into train and test sets (80/20)\n",
    "3. Use an ensemble of decision trees to find the top features for prediction\n",
    "4. Tune the C value (regularization strength) using cross validation\n",
    "5. Instantiate model using optimal value found in the previous step\n",
    "6. Fit model and calculate model accuracy on train and test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results\n",
    "In the end, I trained a Logistic Regression model with the following features: \n",
    "- Egg_Group_1_Undiscovered\n",
    "- Gender_Genderless\n",
    "- Total\n",
    "- Gender_Male\n",
    "- Sp_Atk\n",
    "- Height_m\n",
    "- Attack\n",
    "- Weight_kg\n",
    "- Defense\n",
    "- Egg_Group_1_Mineral\n",
    "\n",
    "The final train accuracy is 98.96%, with the validation accuracy at 99.31%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection Approach\n",
    "\n",
    "I want to predict if a Pokemon is legendary by solving a binary classification problem. Below are 3 options with their respective pros and cons.\n",
    "\n",
    "##### Logistic Regression\n",
    "Pros:\n",
    "- Easy and efficient to compute\n",
    "- Doesn't require input features to be scaled\n",
    "- Easy to interpret\n",
    "- Can trade off between false positive and false negative errors by changing the threshold while still using the same model\n",
    "\n",
    "Cons:\n",
    "- Requires careful feature engineering\n",
    "- Relatively simple model so predictions might not be good enough for complex data\n",
    "\n",
    "##### CART\n",
    "Pros:\n",
    "- Very easy to interpret, even for users without a technical background\n",
    "- Automatically selects the significant variables for us\n",
    "- Can deliver nonlinear predictions\n",
    "\n",
    "Cons: \n",
    "- If we want to modify the loss table then we need to re-run the model\n",
    "- Generally, it is not as accurate as other easy to use methods like logistic regression\n",
    "- Not robust as slight changes in train data can lead to a different tree\n",
    "\n",
    "##### Random Forest\n",
    "Pros:\n",
    "- Powerful algorithm that uses the wisdow of crowds principle\n",
    "- Low variance leads to stable and more accurate predictions\n",
    "\n",
    "Cons:\n",
    "- Uses more computational power due to the need to build many trees\n",
    "- Hard to interpret\n",
    "\n",
    "In the end, I decided to go with logistic regression because this problem is a relatively simple one that could be solved with great results using a simple model. Moreover, when the proper features are selected, logistic regression can deliver accurate predictions with limited computational requirements. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jasperkan/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegressionCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number</th>\n",
       "      <th>Name</th>\n",
       "      <th>Type_1</th>\n",
       "      <th>Type_2</th>\n",
       "      <th>Total</th>\n",
       "      <th>HP</th>\n",
       "      <th>Attack</th>\n",
       "      <th>Defense</th>\n",
       "      <th>Sp_Atk</th>\n",
       "      <th>Sp_Def</th>\n",
       "      <th>...</th>\n",
       "      <th>Color</th>\n",
       "      <th>hasGender</th>\n",
       "      <th>Pr_Male</th>\n",
       "      <th>Egg_Group_1</th>\n",
       "      <th>Egg_Group_2</th>\n",
       "      <th>hasMegaEvolution</th>\n",
       "      <th>Height_m</th>\n",
       "      <th>Weight_kg</th>\n",
       "      <th>Catch_Rate</th>\n",
       "      <th>Body_Style</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Bulbasaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>318</td>\n",
       "      <td>45</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>...</td>\n",
       "      <td>Green</td>\n",
       "      <td>True</td>\n",
       "      <td>0.875</td>\n",
       "      <td>Monster</td>\n",
       "      <td>Grass</td>\n",
       "      <td>False</td>\n",
       "      <td>0.71</td>\n",
       "      <td>6.9</td>\n",
       "      <td>45</td>\n",
       "      <td>quadruped</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Ivysaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>405</td>\n",
       "      <td>60</td>\n",
       "      <td>62</td>\n",
       "      <td>63</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>...</td>\n",
       "      <td>Green</td>\n",
       "      <td>True</td>\n",
       "      <td>0.875</td>\n",
       "      <td>Monster</td>\n",
       "      <td>Grass</td>\n",
       "      <td>False</td>\n",
       "      <td>0.99</td>\n",
       "      <td>13.0</td>\n",
       "      <td>45</td>\n",
       "      <td>quadruped</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Venusaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>525</td>\n",
       "      <td>80</td>\n",
       "      <td>82</td>\n",
       "      <td>83</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>Green</td>\n",
       "      <td>True</td>\n",
       "      <td>0.875</td>\n",
       "      <td>Monster</td>\n",
       "      <td>Grass</td>\n",
       "      <td>True</td>\n",
       "      <td>2.01</td>\n",
       "      <td>100.0</td>\n",
       "      <td>45</td>\n",
       "      <td>quadruped</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Charmander</td>\n",
       "      <td>Fire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>309</td>\n",
       "      <td>39</td>\n",
       "      <td>52</td>\n",
       "      <td>43</td>\n",
       "      <td>60</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>Red</td>\n",
       "      <td>True</td>\n",
       "      <td>0.875</td>\n",
       "      <td>Monster</td>\n",
       "      <td>Dragon</td>\n",
       "      <td>False</td>\n",
       "      <td>0.61</td>\n",
       "      <td>8.5</td>\n",
       "      <td>45</td>\n",
       "      <td>bipedal_tailed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Charmeleon</td>\n",
       "      <td>Fire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>405</td>\n",
       "      <td>58</td>\n",
       "      <td>64</td>\n",
       "      <td>58</td>\n",
       "      <td>80</td>\n",
       "      <td>65</td>\n",
       "      <td>...</td>\n",
       "      <td>Red</td>\n",
       "      <td>True</td>\n",
       "      <td>0.875</td>\n",
       "      <td>Monster</td>\n",
       "      <td>Dragon</td>\n",
       "      <td>False</td>\n",
       "      <td>1.09</td>\n",
       "      <td>19.0</td>\n",
       "      <td>45</td>\n",
       "      <td>bipedal_tailed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Number        Name Type_1  Type_2  Total  HP  Attack  Defense  Sp_Atk  \\\n",
       "0       1   Bulbasaur  Grass  Poison    318  45      49       49      65   \n",
       "1       2     Ivysaur  Grass  Poison    405  60      62       63      80   \n",
       "2       3    Venusaur  Grass  Poison    525  80      82       83     100   \n",
       "3       4  Charmander   Fire     NaN    309  39      52       43      60   \n",
       "4       5  Charmeleon   Fire     NaN    405  58      64       58      80   \n",
       "\n",
       "   Sp_Def  ...  Color  hasGender  Pr_Male Egg_Group_1  Egg_Group_2  \\\n",
       "0      65  ...  Green       True    0.875     Monster        Grass   \n",
       "1      80  ...  Green       True    0.875     Monster        Grass   \n",
       "2     100  ...  Green       True    0.875     Monster        Grass   \n",
       "3      50  ...    Red       True    0.875     Monster       Dragon   \n",
       "4      65  ...    Red       True    0.875     Monster       Dragon   \n",
       "\n",
       "   hasMegaEvolution Height_m Weight_kg  Catch_Rate      Body_Style  \n",
       "0             False     0.71       6.9          45       quadruped  \n",
       "1             False     0.99      13.0          45       quadruped  \n",
       "2              True     2.01     100.0          45       quadruped  \n",
       "3             False     0.61       8.5          45  bipedal_tailed  \n",
       "4             False     1.09      19.0          45  bipedal_tailed  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the CSV and store data in a dataframe\n",
    "stats = pd.read_csv('pokemon_data_science.csv')\n",
    "\n",
    "# quick look at the dataframe\n",
    "stats.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handling null values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's see if there are any null values in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Number                0\n",
       "Name                  0\n",
       "Type_1                0\n",
       "Type_2              371\n",
       "Total                 0\n",
       "HP                    0\n",
       "Attack                0\n",
       "Defense               0\n",
       "Sp_Atk                0\n",
       "Sp_Def                0\n",
       "Speed                 0\n",
       "Generation            0\n",
       "isLegendary           0\n",
       "Color                 0\n",
       "hasGender             0\n",
       "Pr_Male              77\n",
       "Egg_Group_1           0\n",
       "Egg_Group_2         530\n",
       "hasMegaEvolution      0\n",
       "Height_m              0\n",
       "Weight_kg             0\n",
       "Catch_Rate            0\n",
       "Body_Style            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After some research on Pokemon, I found out that not all Pokemon have a secondary type and egg group. Therefore, it is possible for values in these two columns to be null. I will replace the null values with 'NA' for these two features later on.\n",
    "\n",
    "Let's dig a little deeper into the Pr_Male column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats[stats['Pr_Male'].isnull()]['hasGender'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats[stats['Pr_Male'].notnull()]['hasGender'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pr_Male is null only when a Pokemon is genderless. It is hard to find a value as a replacement for nulls in Pr_Male. Therefore, I decided to create a new (expected) Gender column to replace Pr_Male.\n",
    "\n",
    "If Pr_Male >= 0.5, then we will classify the Pokemon as a Male. If < 0.5, Female. If null, Genderless. \n",
    "\n",
    "hasGender and Pr_Male will be dropped later to prevent multicollinearity.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Male          597\n",
       "Genderless     77\n",
       "Female         47\n",
       "Name: Gender, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if Pr_Male >= 0.5, then Male\n",
    "# if Pr_Male < 0.5, then Female\n",
    "# if null, then Genderless\n",
    "stats['Gender'] = np.where(stats['Pr_Male']>=0.5, 'Male', \n",
    "                           np.where(stats['Pr_Male'].notnull(), 'Female', 'Genderless'))\n",
    "stats['Gender'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I can safely replace the remaining null values with 'NA'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Number              0\n",
       "Name                0\n",
       "Type_1              0\n",
       "Type_2              0\n",
       "Total               0\n",
       "HP                  0\n",
       "Attack              0\n",
       "Defense             0\n",
       "Sp_Atk              0\n",
       "Sp_Def              0\n",
       "Speed               0\n",
       "Generation          0\n",
       "isLegendary         0\n",
       "Color               0\n",
       "hasGender           0\n",
       "Pr_Male             0\n",
       "Egg_Group_1         0\n",
       "Egg_Group_2         0\n",
       "hasMegaEvolution    0\n",
       "Height_m            0\n",
       "Weight_kg           0\n",
       "Catch_Rate          0\n",
       "Body_Style          0\n",
       "Gender              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.fillna('NA', inplace=True)\n",
    "\n",
    "# check\n",
    "stats.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will drop the unnecessary columns before further processing the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# catch_rate will be dropped because it will not be used per the given instructions\n",
    "stats.drop(columns=['Catch_Rate', 'Pr_Male', 'hasGender'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handling categorical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to convert boolean values and categorical variables into numeric values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Number                int64\n",
       "Name                 object\n",
       "Type_1               object\n",
       "Type_2               object\n",
       "Total                 int64\n",
       "HP                    int64\n",
       "Attack                int64\n",
       "Defense               int64\n",
       "Sp_Atk                int64\n",
       "Sp_Def                int64\n",
       "Speed                 int64\n",
       "Generation            int64\n",
       "isLegendary            bool\n",
       "Color                object\n",
       "Egg_Group_1          object\n",
       "Egg_Group_2          object\n",
       "hasMegaEvolution       bool\n",
       "Height_m            float64\n",
       "Weight_kg           float64\n",
       "Body_Style           object\n",
       "Gender               object\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now, let's see what columns we need to make changes to\n",
    "stats.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats['isLegendary'] = stats['isLegendary'].astype('int64')\n",
    "stats['hasMegaEvolution'] = stats['hasMegaEvolution'].astype('int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using One Hot Encoding to create dummy variables, we will only create k-1 variables for k distinct values to prevent multicollinearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop_first = True to prevent multicollinearity\n",
    "col = ['Type_1', 'Type_2', 'Color', 'Egg_Group_1', 'Egg_Group_2', 'Body_Style', 'Gender']\n",
    "stats = pd.get_dummies(stats, columns=col, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Number                           int64\n",
       "Name                            object\n",
       "Total                            int64\n",
       "HP                               int64\n",
       "Attack                           int64\n",
       "Defense                          int64\n",
       "Sp_Atk                           int64\n",
       "Sp_Def                           int64\n",
       "Speed                            int64\n",
       "Generation                       int64\n",
       "isLegendary                      int64\n",
       "hasMegaEvolution                 int64\n",
       "Height_m                       float64\n",
       "Weight_kg                      float64\n",
       "Type_1_Dark                      uint8\n",
       "Type_1_Dragon                    uint8\n",
       "Type_1_Electric                  uint8\n",
       "Type_1_Fairy                     uint8\n",
       "Type_1_Fighting                  uint8\n",
       "Type_1_Fire                      uint8\n",
       "Type_1_Flying                    uint8\n",
       "Type_1_Ghost                     uint8\n",
       "Type_1_Grass                     uint8\n",
       "Type_1_Ground                    uint8\n",
       "Type_1_Ice                       uint8\n",
       "Type_1_Normal                    uint8\n",
       "Type_1_Poison                    uint8\n",
       "Type_1_Psychic                   uint8\n",
       "Type_1_Rock                      uint8\n",
       "Type_1_Steel                     uint8\n",
       "Type_1_Water                     uint8\n",
       "Type_2_Dark                      uint8\n",
       "Type_2_Dragon                    uint8\n",
       "Type_2_Electric                  uint8\n",
       "Type_2_Fairy                     uint8\n",
       "Type_2_Fighting                  uint8\n",
       "Type_2_Fire                      uint8\n",
       "Type_2_Flying                    uint8\n",
       "Type_2_Ghost                     uint8\n",
       "Type_2_Grass                     uint8\n",
       "Type_2_Ground                    uint8\n",
       "Type_2_Ice                       uint8\n",
       "Type_2_NA                        uint8\n",
       "Type_2_Normal                    uint8\n",
       "Type_2_Poison                    uint8\n",
       "Type_2_Psychic                   uint8\n",
       "Type_2_Rock                      uint8\n",
       "Type_2_Steel                     uint8\n",
       "Type_2_Water                     uint8\n",
       "Color_Blue                       uint8\n",
       "Color_Brown                      uint8\n",
       "Color_Green                      uint8\n",
       "Color_Grey                       uint8\n",
       "Color_Pink                       uint8\n",
       "Color_Purple                     uint8\n",
       "Color_Red                        uint8\n",
       "Color_White                      uint8\n",
       "Color_Yellow                     uint8\n",
       "Egg_Group_1_Bug                  uint8\n",
       "Egg_Group_1_Ditto                uint8\n",
       "Egg_Group_1_Dragon               uint8\n",
       "Egg_Group_1_Fairy                uint8\n",
       "Egg_Group_1_Field                uint8\n",
       "Egg_Group_1_Flying               uint8\n",
       "Egg_Group_1_Grass                uint8\n",
       "Egg_Group_1_Human-Like           uint8\n",
       "Egg_Group_1_Mineral              uint8\n",
       "Egg_Group_1_Monster              uint8\n",
       "Egg_Group_1_Undiscovered         uint8\n",
       "Egg_Group_1_Water_1              uint8\n",
       "Egg_Group_1_Water_2              uint8\n",
       "Egg_Group_1_Water_3              uint8\n",
       "Egg_Group_2_Bug                  uint8\n",
       "Egg_Group_2_Dragon               uint8\n",
       "Egg_Group_2_Fairy                uint8\n",
       "Egg_Group_2_Field                uint8\n",
       "Egg_Group_2_Flying               uint8\n",
       "Egg_Group_2_Grass                uint8\n",
       "Egg_Group_2_Human-Like           uint8\n",
       "Egg_Group_2_Mineral              uint8\n",
       "Egg_Group_2_Monster              uint8\n",
       "Egg_Group_2_NA                   uint8\n",
       "Egg_Group_2_Water_1              uint8\n",
       "Egg_Group_2_Water_2              uint8\n",
       "Egg_Group_2_Water_3              uint8\n",
       "Body_Style_bipedal_tailless      uint8\n",
       "Body_Style_four_wings            uint8\n",
       "Body_Style_head_arms             uint8\n",
       "Body_Style_head_base             uint8\n",
       "Body_Style_head_legs             uint8\n",
       "Body_Style_head_only             uint8\n",
       "Body_Style_insectoid             uint8\n",
       "Body_Style_multiple_bodies       uint8\n",
       "Body_Style_quadruped             uint8\n",
       "Body_Style_serpentine_body       uint8\n",
       "Body_Style_several_limbs         uint8\n",
       "Body_Style_two_wings             uint8\n",
       "Body_Style_with_fins             uint8\n",
       "Gender_Genderless                uint8\n",
       "Gender_Male                      uint8\n",
       "dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that all features are in the proper format, we will create a dataframe with just the features to perform feature engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training feature df\n",
    "X = stats.copy()\n",
    "X.drop(columns=['Number', 'Name', 'isLegendary'], inplace=True)\n",
    "y = stats['isLegendary']\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, \n",
    "                                                  y, \n",
    "                                                  test_size=0.2, \n",
    "                                                  random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will use an ensemble of decision trees to find the top 10 best features for prediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 best features: [65 95  0 96  4  9  2 10  3 63]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Egg_Group_1_Undiscovered',\n",
       " 'Gender_Genderless',\n",
       " 'Total',\n",
       " 'Gender_Male',\n",
       " 'Sp_Atk',\n",
       " 'Height_m',\n",
       " 'Attack',\n",
       " 'Weight_kg',\n",
       " 'Defense',\n",
       " 'Egg_Group_1_Mineral']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standard_X = StandardScaler().fit_transform(X_train) \n",
    "model = ExtraTreesClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "n_best_features=10\n",
    "model.fit(standard_X, y_train)\n",
    "important_features = model.feature_importances_\n",
    "best_features = important_features.argsort()[-n_best_features:][::-1]\n",
    "print(f\"Top {n_best_features} best features: {best_features}\")\n",
    "\n",
    "features = []\n",
    "for i in best_features:\n",
    "    features.append(X.columns[i])\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will now exclude all the unselected features from the dataframe and prepare the final training and validation datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = stats[features]\n",
    "y = stats['isLegendary']\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, \n",
    "                                                  y, \n",
    "                                                  test_size=0.2, \n",
    "                                                  random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will use the LogisticRegressionCV class from sklearn, which is an estimator that has built-in cross-validation capabilities to automatically select the best hyper-parameters. \n",
    "\n",
    "In this case, the hyper-parameter I will tune is the C value, which describes the inverse of regularization strength. Smaller C values specify stronger regularization.\n",
    "\n",
    "By default, the model will predict Y = 1 if p > 0.5. Depending on what the expected reward and loss are for correct and incorrect classifications respectively, we may choose to predict using a different threshold. However, to keep this model simple, we will use 0.5 as the threshold for now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train labeling accuracy: 98.96 %\n",
      "Validation labeling accuracy: 99.31 %\n",
      "\n",
      "Confusion matrix:\n",
      " [[136   1]\n",
      " [  0   8]]\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegressionCV(cv=10, random_state=42)\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "acc_train = logreg.score(X_train, y_train)\n",
    "y_pred = logreg.predict(X_val)\n",
    "acc_val = logreg.score(X_val, y_val)   \n",
    "\n",
    "confusion_matrix = metrics.confusion_matrix(y_val, y_pred)\n",
    "\n",
    "print('Train labeling accuracy:', str(round(acc_train*100,2)),'%')\n",
    "print('Validation labeling accuracy:', str(round(acc_val*100,2)),'%')\n",
    "print('\\nConfusion matrix:\\n', confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "In the end, I trained a Logistic Regression model with the following features: \n",
    "- Egg_Group_1_Undiscovered\n",
    "- Gender_Genderless\n",
    "- Total\n",
    "- Gender_Male\n",
    "- Sp_Atk\n",
    "- Height_m\n",
    "- Attack\n",
    "- Weight_kg\n",
    "- Defense\n",
    "- Egg_Group_1_Mineral\n",
    "\n",
    "10-fold CV is performed to select the best L2 regularization strength. The training and validation test sets are created using a 80/20 split.\n",
    "\n",
    "The final train accuracy is 98.96%, with the validation accuracy at 99.31%."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
